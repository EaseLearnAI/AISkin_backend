QVQ模型具有强大的视觉推理能力，它能够先输出思考过程，再输出回答内容。QVQ 模型当前仅支持通过流式输出方式调用。

本文介绍的 QVQ 模型使用方法不适用于 qvq-72b-preview，如果您使用 qvq-72b-preview 模型，请参考视觉理解。
支持的模型
QVQ是视觉推理模型，支持视觉输入及思维链输出，在数学、编程、视觉分析、创作以及通用任务上都表现了更强的能力。

模型名称

版本

上下文长度

最大输入

最大思维链长度

最大回复长度

输入成本

输出成本

免费额度

（注）

（Token数）

（每千Token）

模型名称

版本

上下文长度

最大输入

最大思维链长度

最大回复长度

输入成本

输出成本

免费额度

（注）

（Token数）

（每千Token）

qvq-max

相比 qvq-plus 具有更强的视觉推理和指令遵循能力，在更多复杂任务中提供最佳性能。
当前与qvq-max-2025-03-25能力相同
稳定版

131,072

106,496

单图最大16384
16,384

8,192

0.008元

0.032元

各100万 Token

有效期：百炼开通后180天内

qvq-max-latest

始终与最新快照版能力相同
最新版

qvq-max-2025-05-15

又称qvq-max-0515
快照版

qvq-max-2025-03-25

又称qvq-max-0325
qvq-plus

当前与qvq-plus-2025-05-15能力相同
稳定版

0.002元

0.005元

qvq-plus-latest

始终与最新快照版能力相同
最新版

qvq-plus-2025-05-15

又称qvq-plus-0515
快照版

图像与视频转换为Token的规则

下面是传入图像URL进行视觉推理的示例代码。

您可以在使用说明处查看对输入图像的限制，如需传入本地图像请参见使用本地文件
OpenAI兼容DashScope
PythonNode.jsHTTP
示例代码
 
import OpenAI from "openai";
import process from 'process';

// 初始化 openai 客户端
const openai = new OpenAI({
    apiKey: process.env.DASHSCOPE_API_KEY, // 从环境变量读取
    baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1'
});

let reasoningContent = '';
let answerContent = '';
let isAnswering = false;

let messages = [
    {
        role: "user",
        content: [
        { type: "image_url", image_url: { "url": "https://img.alicdn.com/imgextra/i1/O1CN01gDEY8M1W114Hi3XcN_!!6000000002727-0-tps-1024-406.jpg" } },
        { type: "text", text: "解答这道题" },
    ]
}]

async function main() {
    try {
        const stream = await openai.chat.completions.create({
            model: 'qvq-max',
            messages: messages,
            stream: true
        });

        console.log('\n' + '='.repeat(20) + '思考过程' + '='.repeat(20) + '\n');

        for await (const chunk of stream) {
            if (!chunk.choices?.length) {
                console.log('\nUsage:');
                console.log(chunk.usage);
                continue;
            }

            const delta = chunk.choices[0].delta;

            // 处理思考过程
            if (delta.reasoning_content) {
                process.stdout.write(delta.reasoning_content);
                reasoningContent += delta.reasoning_content;
            }
            // 处理正式回复
            else if (delta.content) {
                if (!isAnswering) {
                    console.log('\n' + '='.repeat(20) + '完整回复' + '='.repeat(20) + '\n');
                    isAnswering = true;
                }
                process.stdout.write(delta.content);
                answerContent += delta.content;
            }
        }
    } catch (error) {
        console.error('Error:', error);
    }
}

main();
点击查看思考过程和完整回复

多轮对话
QVQ 模型 API 默认不会记录您的历史对话信息。多轮对话功能可以让大模型“拥有记忆”，满足如追问、信息采集等需要连续交流的场景。您在使用 QVQ 模型时，会接收到reasoning_content字段（思考过程）与content（回复内容），您可以将content字段通过{'role': 'assistant', 'content':拼接后的流式输出content}添加到上下文，无需添加reasoning_content字段。

OpenAI兼容DashScope
您可以通过 OpenAI SDK 或 OpenAI 兼容的 HTTP 方式使用多轮对话功能。

PythonNode.jsHTTP
示例代码
 
import OpenAI from "openai";
import process from 'process';
import readline from 'readline/promises';

// 初始化 readline 接口
const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
});

// 初始化 openai 客户端
const openai = new OpenAI({
    apiKey: process.env.DASHSCOPE_API_KEY, // 从环境变量读取
    baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1'
});

let reasoningContent = '';
let answerContent = '';
let isAnswering = false;
let messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://img.alicdn.com/imgextra/i1/O1CN01gDEY8M1W114Hi3XcN_!!6000000002727-0-tps-1024-406.jpg"
                },
            },
            {"type": "text", "text": "请解答这道题"},
        ],
    }
];
let conversationIdx = 1;

async function main() {
    while (true) {
        let reasoningContent = '';
        let answerContent = '';
        let isAnswering = false;
        console.log("=".repeat(20) + `第${conversationIdx}轮对话` + "=".repeat(20));
        conversationIdx++;

        // 重置状态
        reasoningContent = '';
        answerContent = '';
        isAnswering = false;

        try {
            const stream = await openai.chat.completions.create({
                model: 'qvq-max',
                messages: messages,
                stream: true
            });

            console.log("\n" + "=".repeat(20) + "思考过程" + "=".repeat(20) + "\n");

            for await (const chunk of stream) {
                if (!chunk.choices?.length) {
                    console.log('\nUsage:');
                    console.log(chunk.usage);
                    continue;
                }

                const delta = chunk.choices[0].delta;

                // 处理思考过程
                if (delta.reasoning_content) {
                    process.stdout.write(delta.reasoning_content);
                    reasoningContent += delta.reasoning_content;
                }

                // 处理正式回复
                if (delta.content) {
                    if (!isAnswering) {
                        console.log('\n' + "=".repeat(20) + "完整回复" + "=".repeat(20) + "\n");
                        isAnswering = true;
                    }
                    process.stdout.write(delta.content);
                    answerContent += delta.content;
                }
            }

            // 将完整回复加入消息历史
            messages.push({ role: 'assistant', content: answerContent });
            const userInput = await rl.question("请输入你的消息：");
            messages.push({"role": "user", "content":userInput});

            console.log("\n");

        } catch (error) {
            console.error('Error:', error);
        }
    }
}

// 启动程序
main().catch(console.error);
多图像输入
QVQ模型可在一次请求中同时输入多张图像，模型会根据传入的全部图像进行回答。传入方式为图像URL或本地文件，也支持二者组合传入，下面是以图像URL方式传入的示例代码。

输入图像的总Token数必须小于模型的最大输入，您可以参考图像数量限制，计算可传入图像的最大数量。
OpenAI兼容DashScope
PythonNode.jscurl
 
import OpenAI from "openai";
import process from 'process';

// 初始化 openai 客户端
const openai = new OpenAI({
    apiKey: process.env.DASHSCOPE_API_KEY, // 从环境变量读取
    baseURL: 'https://dashscope.aliyuncs.com/compatible-mode/v1'
});

let reasoningContent = '';
let answerContent = '';
let isAnswering = false;

let messages = [
        {role: "user",content: [
        // 第一张图像链接，如果传入本地文件，请将url的值替换为图像的Base64编码格式
            {type: "image_url",image_url: {"url": "https://img.alicdn.com/imgextra/i1/O1CN01gDEY8M1W114Hi3XcN_!!6000000002727-0-tps-1024-406.jpg"}},
            // 第二张图像链接，如果传入本地文件，请将url的值替换为图像的Base64编码格式
            {type: "image_url",image_url: {"url": "https://img.alicdn.com/imgextra/i1/O1CN01ukECva1cisjyK6ZDK_!!6000000003635-0-tps-1500-1734.jpg"}},
            {type: "text", text: "解答第一张图像中的题目，然后再解读第二张图的文章。" },
        ]}]

async function main() {
    try {
        const stream = await openai.chat.completions.create({
            model: 'qvq-max',
            messages: messages,
            stream: true
        });

        console.log('\n' + '='.repeat(20) + '思考过程' + '='.repeat(20) + '\n');

        for await (const chunk of stream) {
            if (!chunk.choices?.length) {
                console.log('\nUsage:');
                console.log(chunk.usage);
                continue;
            }

            const delta = chunk.choices[0].delta;

            // 处理思考过程
            if (delta.reasoning_content) {
                process.stdout.write(delta.reasoning_content);
                reasoningContent += delta.reasoning_content;
            }
            // 处理正式回复
            else if (delta.content) {
                if (!isAnswering) {
                    console.log('\n' + '='.repeat(20) + '完整回复' + '='.repeat(20) + '\n');
                    isAnswering = true;
                }
                process.stdout.write(delta.content);
                answerContent += delta.content;
            }
        }
    } catch (error) {
        console.error('Error:', error);
    }
}

main();

使用说明
支持的图像
模型支持的图像格式如下表，需注意在使用OpenAI SDK 传入本地图像时，请根据实际的图像格式，将代码中的image/{format}设置为对应的Content Type值。




图像格式

文件扩展名

Content Type

BMP

.bmp

image/bmp

JPEG

.jpe, .jpeg, .jpg

image/jpeg

PNG

.png

image/png

TIFF

.tif, .tiff

image/tiff

WEBP

.webp

image/webp

HEIC

.heic

image/heic

图像大小限制
单个图像文件的大小不超过10 MB。其中使用OpenAI SDK方式传入本地图像时，需保证Base64编码后的图像大小不超过10MB，详情请参见传入本地文件。

图像的宽度和高度均应大于10像素，宽高比不应超过200:1或1:200。

对单图的像素总数无限制，因为模型在进行图像理解前会对图像进行缩放等预处理。过大的图像不会有更好的理解效果，推荐的像素值如下：

输入qvq-max、qvq-max-latest、qvq-max-2025-03-25模型的单张图像，像素数推荐不超过1003520。

图像数量限制
在多图像输入中，图像数量受模型图文总Token上限（即最大输入）的限制，所有图像的总Token数必须小于模型的最大输入。

如：qvq-max模型的最大输入为 106496 Token，单图默认Token上限1280，可在DashScope方式中设置vl_high_resolution_images参数，将Token上限提高至16384，若传入的图像像素均为1280 × 1280：





单图Token上限

调整后的图像宽高

图像Token数

最多可传入的图像数量（张）

1280（默认值）

980 x 980

1227

86

16384

1288 x 1288

2118

50